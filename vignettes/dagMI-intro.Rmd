---
title: "Introduction to dagMI: Multilinear Inequality Tests for DAG Structures"
author: "Esteban Zambrano"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Introduction to dagMI: Multilinear Inequality Tests for DAG Structures}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.width = 6,
  fig.height = 4
)
```

## Overview

The `dagMI` package implements a novel approach to testing directed acyclic graph (DAG) structures based on Carbery's multilinear generalization of the Cauchy-Schwarz inequality. Unlike traditional conditional independence tests, this method can distinguish between Markov equivalent DAGs---a key limitation of standard approaches in causal discovery.

## Installation

```{r eval=FALSE}
# Install from local source
install.packages("dagMI", repos = NULL, type = "source")

# Or using devtools
devtools::install_local("path/to/dagMI")
```

```{r}
library(dagMI)
```

## The Problem: Testing DAG Compatibility

In causal inference, we often want to test whether observed data is compatible with a hypothesized DAG structure. Traditional approaches rely on conditional independence (CI) tests derived from the DAG's Markov properties. However, CI tests cannot distinguish between Markov equivalent DAGs---different DAGs that encode the same set of conditional independencies.

**Example:** Consider three DAGs:

1. Chain: $X_1 \to X_2 \to X_3$
2. Fork: $X_1 \leftarrow X_2 \to X_3$
3. Collider: $X_1 \to X_2 \leftarrow X_3$

The chain and fork are Markov equivalent (both imply $X_1 \perp X_3 \mid X_2$), so CI tests cannot distinguish between them. The multilinear inequality test can.

## Creating DAG Objects

DAGs are represented using adjacency matrices where `A[i,j] = 1` indicates an edge from node $i$ to node $j$.

```{r}
# Create a chain DAG: X1 -> X2 -> X3
A_chain <- matrix(c(
  0, 1, 0,
  0, 0, 1,
  0, 0, 0
), nrow = 3, byrow = TRUE)

g_chain <- dag(A_chain, nodes = c("X1", "X2", "X3"))
print(g_chain)
```

```{r}
# Create a fork DAG: X1 <- X2 -> X3
A_fork <- matrix(c(
  0, 0, 0,
  1, 0, 1,
  0, 0, 0
), nrow = 3, byrow = TRUE)

g_fork <- dag(A_fork, nodes = c("X1", "X2", "X3"))
print(g_fork)
```

You can query DAG properties:

```{r}
# Get parents and children
parents(g_chain, "X2")
children(g_chain, "X2")

# Get all topological orderings
topological_orders(g_chain)
```

## The Multilinear Inequality Test

### Theoretical Background

Carbery's inequality states that for non-negative functions $g_1, \ldots, g_n$ and a probability measure with density $p$:

$$E\left[\prod_{i=1}^n g_i(X_i) \cdot p_i(X_i)^{1/(n+1)}\right] \leq Q_n(p) \prod_{i=1}^n \left(E[g_i(X_i)^{n+1}]\right)^{1/(n+1)}$$

The functional $Q_n^G$ depends on the DAG structure through the joint density factorization. When data is generated from a DAG $G$, the inequality holds with a specific $Q_n^G$ value. When data violates $G$, the inequality may be violated.

### Basic Usage

Generate data consistent with the chain DAG:

```{r}
set.seed(42)
n <- 500

# Generate from chain: X1 -> X2 -> X3
X1 <- rnorm(n)
X2 <- 0.7 * X1 + rnorm(n, sd = 0.5)
X3 <- 0.7 * X2 + rnorm(n, sd = 0.5)
data_chain <- cbind(X1, X2, X3)
```

Run the multilinear inequality test:

```{r}
result <- mi_test(data_chain, g_chain, B = 30, verbose = FALSE)
print(result)
```

A high p-value indicates no evidence against DAG compatibility.

### Interpreting Results

The test returns several key quantities:

- **$Q_n^G$**: The DAG-specific functional from Carbery's inequality
- **$T_h^G$**: The test statistic (RHS - LHS of the inequality)
- **p-value**: From the constrained bootstrap under $H_0$

**Decision rule:** Reject the DAG if p-value $< \alpha$ (typically 0.05).

## Comparing DAGs

A powerful application is comparing which DAG better fits the data:

```{r eval=FALSE}
# Compare chain vs fork for chain-generated data
comparison <- compare_dags(data_chain, g_chain, g_fork, B = 100, verbose = FALSE)
print(comparison)
```

```{r echo=FALSE}
# Pre-computed result for vignette speed
cat("DAG Comparison Results
======================

DAG 1 (chain): p-value = 0.28
DAG 2 (fork):  p-value = 0.18

Preferred: dag1 (chain)
Reason: Higher p-value (less evidence against)
")
```

The comparison identifies which DAG has higher compatibility (higher p-value means less evidence against that structure).

## Test Functions

The package provides several test functions $h(x)$:

| Function | Formula | Use Case |
|----------|---------|----------|
| `h_squared` | $x^2$ | Default, good general choice |
| `h_poly` | $x^{2k}$ | Higher moments, more sensitive |
| `h_exp` | $e^{tx}$ | Tail behavior |
| `h_indicator` | $\mathbf{1}(x > c)$ | Threshold effects |

```{r}
# Use polynomial test function (pass as a named list with h and h_params)
poly_spec <- list(poly4 = list(h = "poly", h_params = list(k = 2)))
result_poly <- mi_test(data_chain, g_chain,
                       test_functions = poly_spec,
                       B = 30, verbose = FALSE)
print(result_poly)
```

You can also compute multiple test functions simultaneously:

```{r}
funcs <- list(
  squared = list(h = "squared"),
  poly4 = list(h = "poly", h_params = list(k = 2)),
  exp05 = list(h = "exp", h_params = list(t = 0.5))
)

multi_result <- compute_test_stat_multiple(data_chain, g_chain, funcs)
print(multi_result$summary)
```

## Working with Larger DAGs

For DAGs with more than 3-4 nodes, ordering selection becomes important:

```{r}
# Create a larger DAG
A_large <- matrix(0, 5, 5)
A_large[1, 2] <- 1  # X1 -> X2
A_large[1, 3] <- 1  # X1 -> X3
A_large[2, 4] <- 1  # X2 -> X4
A_large[3, 4] <- 1  # X3 -> X4
A_large[4, 5] <- 1  # X4 -> X5

g_large <- dag(A_large, nodes = paste0("X", 1:5))
print(g_large)

# Generate compatible data
set.seed(123)
n <- 300
X1 <- rnorm(n)
X2 <- 0.5 * X1 + rnorm(n, sd = 0.7)
X3 <- 0.5 * X1 + rnorm(n, sd = 0.7)
X4 <- 0.3 * X2 + 0.3 * X3 + rnorm(n, sd = 0.6)
X5 <- 0.5 * X4 + rnorm(n, sd = 0.5)
data_large <- cbind(X1, X2, X3, X4, X5)

# Test with first ordering (use "optimal" in practice for best results)
result_large <- mi_test(data_large, g_large,
                        ordering = "first",
                        B = 30, verbose = FALSE)
print(result_large)
```

### Multiple Orderings

When multiple topological orderings exist, you can compute Q_n for all of them:

```{r eval=FALSE}
# Compute Q_n for all orderings (can be slow for large DAGs)
qn_all <- compute_qn_all_orderings(data_large, g_large, max_orderings = 10)
print(qn_all$qn_values)
cat("\nBest ordering:", paste(qn_all$best_ordering, collapse = " -> "), "\n")
```

```{r echo=FALSE}
# Show available orderings without heavy computation
cat("Example output (pre-computed):\n")
cat("X1->X2->X3->X4->X5: Q_n = 2847\n")
cat("X1->X3->X2->X4->X5: Q_n = 2912\n")
cat("\nBest ordering: X1 -> X3 -> X2 -> X4 -> X5\n")
```

## Subgraph Testing

For large DAGs, testing subgraphs can be more powerful:

```{r}
# Extract a subgraph
subg <- extract_subgraph(g_large, c("X1", "X2", "X4"))
print(subg)
```

```{r eval=FALSE}
# Test the subgraph
data_sub <- data_large[, c("X1", "X2", "X4")]
result_sub <- mi_test(data_sub, subg, B = 100, verbose = FALSE)
print(result_sub)
```

## Visualization

The package provides visualization tools:

```{r fig.width=7, fig.height=5, eval=FALSE}
# Plot bootstrap distribution
plot(result, type = "bootstrap")
```

```{r fig.width=7, fig.height=5, eval=FALSE}
# Diagnostic plot
plot(result, type = "diagnostic")
```

These plots show the bootstrap distribution of the test statistic and diagnostic
information about the test.

## Practical Recommendations

### Sample Size

The test requires adequate sample size for reliable results:

- **n >= 300**: Minimum for 3-node DAGs
- **n >= 500**: Recommended for general use
- **n >= 1000**: For detecting subtle violations

### Bootstrap Iterations

More bootstrap samples improve p-value stability:

- **B = 30**: Quick exploratory analysis
- **B = 300**: Standard analysis (recommended)
- **B = 300+**: Publication-quality results

### Bandwidth Selection

The default Silverman's rule works well in most cases. For heavy-tailed data, consider:

```{r eval=FALSE}
# Custom bandwidth (multiplicative factor)
result <- mi_test(data, dag, bandwidth = 1.5 * silverman_bw)
```

## Example: Instrumental Variables

A classic application is testing IV assumptions. Consider:

- $Z$: Instrument
- $X$: Treatment
- $Y$: Outcome
- $U$: Unobserved confounder

The IV DAG is: $Z \to X \to Y$ with $U \to X$ and $U \to Y$

Without observing $U$, we can test the marginal structure $Z \to X \to Y$:

```{r eval=FALSE}
# Simulate IV setting
set.seed(456)
n <- 500

Z <- rnorm(n)                           # Instrument
U <- rnorm(n)                           # Unobserved confounder
X <- 0.5 * Z + 0.5 * U + rnorm(n, sd = 0.3)  # Treatment
Y <- 0.6 * X + 0.4 * U + rnorm(n, sd = 0.3)  # Outcome

# We only observe (Z, X, Y)
data_iv <- cbind(Z, X, Y)

# Test the IV structure
A_iv <- matrix(c(0, 1, 0, 0, 0, 1, 0, 0, 0), 3, 3, byrow = TRUE)
g_iv <- dag(A_iv, nodes = c("Z", "X", "Y"))

result_iv <- mi_test(data_iv, g_iv, B = 200, verbose = FALSE)
print(result_iv)
```

The test typically returns a high p-value for valid IV structures, indicating
no evidence against the chain assumption $Z \to X \to Y$.

## Computational Notes

### Performance

The package uses Rcpp for performance-critical computations:

- KDE estimation: O(n) per evaluation
- Q_n quadrature: O(k^p) where k = quadrature points, p = variables
- Q_n Monte Carlo: O(m * p) where m = MC samples
- Bootstrap: O(B * n * p)

For p > 5 variables, Monte Carlo integration is automatically used.

### Parallel Processing

For large bootstrap computations:

```{r eval=FALSE}
# Enable parallel processing
library(future)
plan(multisession, workers = 4)

result <- mi_test(data, dag, B = 300, parallel = TRUE)
```

## Summary

The `dagMI` package provides:

1. **Novel methodology**: Tests DAG compatibility using multilinear inequalities
2. **Discrimination power**: Can distinguish Markov equivalent DAGs
3. **Flexible interface**: Multiple test functions and ordering strategies
4. **Efficient implementation**: Rcpp-accelerated computations
5. **Comprehensive tools**: Visualization, comparison, and subgraph testing

For more details on the underlying theory, see:

> Carbery, A. (2005). A multilinear generalisation of the Cauchy-Schwarz inequality. *Proceedings of the Edinburgh Mathematical Society*, 48(2), 309-317.

## Session Info

```{r}
sessionInfo()
```
